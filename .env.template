# File that contains different config for environment

# Password used for grafana that is spun up with the stack.
# Default username is `admin`
GF_SECURITY_ADMIN_PASSWORD=password

# Domain name for the stack which helps other parts know
# what url should they adjust the frontend links to.
# Needed because of nginx
DOMAIN_NAME=localhost:8000

# Nginx port to bind to. This port and the port in the
# `DOMAIN_NAME` have to be the same for all parts of
# the stack to work properly
NGINX_PORT=8000

# Connection string for database. Locally you can leave
# this password since it is configured to run against
# a local stack.
CONNECTION_STRING="Host=postgres;Username=postgres;Password=postgres;Database=postgres"

# Url to connect to s3. Locally it should be like this
# since we use minio to mock s3. Even if we are in the
# docker environment, in code we setup a proxy for minio
# on correct urls.
AWS_S3_URL="http://localhost:9002"

# Region to use for s3. Locally it can be left as is.
AWS_REGION="localhost"

# Access key for s3. It is created when the s3 is
# provisioned. For local development can be left
# as is since they represent minio username
AWS_S3_ACCESS_KEY="admin"

# Secret key for s3. It is created when the s3 is
# provisioned. For local development can be left
# as is since they represent minio password
AWS_S3_SECRET_KEY="admin123"

# Aws protocol to use to generate presigned urls.
# For production it should be https. For dev it
# should be http.
AWS_PROTOCOL="http"

# Url to connect to sqs. Locally it should be like this
# since we use elasticmq to mock sqs.
AWS_SQS_URL="http://sqs:9324"

# Sqs access key to connect to the service. For local
# development it can be left as 'x'
AWS_SQS_ACCESS_KEY=x

# Sqs secret key to connect to the service. For local
# development it can be left as 'x'
AWS_SQS_SECRET_KEY=x

# Url of the queue to listen to for updates from the
# users. For development leave as is
AWS_SQS_NONPROCESSED_QUEUE_URL=/000000000000/nonprocessed

# Specifies wether backend will check if the device
# exists in the database before allowing it to
# connect. For development its easier to have this
# at false but tests should cover it being at true
# as well.
REQUIRE_KNOWN_DEVICES=false

### BUCKET SETUP
### Required since S3 doesn't allow
### for arbitrary bucket creation on the fly
### (With reliable names).

# Bucket where processed videos will be stored
PROCESSED_BUCKET_NAME="processed"
# Bucket where nonprocessed videos will be stored
NON_PROCESSED_BUCKET_NAME="non-processed"
# Bucket for schedules
SCHEDULE_BUCKET_NAME="schedule"

### CRON SETUP
### For all crons we use crontab which and all crons
### have to be vaild according to this formatter
### https://www.freeformatter.com/cron-expression-generator-quartz.html
### These values don't have to be specified and in that
### case the default value of "0/15 * * ? * *" will
### be used. For tests its required to specify them.

# Interval at which backend will send noop signal
# to all connected devices
NOOP_CRON="0/15 * * ? * *"

# Interval at which backend will query sqs to
# see if there are any new messages to be handled
SQS_CRON="0/15 * * ? * *"

# Max delay per device when the backend has to
# call a device for schedule. This has to be able
# to be parsed in a TimeSpan object
SCHEDULE_MAX_DELAY="00:01:00"
# Maximum amount of devices per batch that backend
# will call at once. If the threshold is reached
# backend will reduce the amount of letters in
# a batch and recalculate.
SCHEDULE_DEVICE_THRESHOLD=100

# Maximum amount of ads to include in the batch
CALCULATE_AD_THRESHOLD=10
# Expiration timespan for the presigned urls of ads
CALCULATE_URL_EXPIRE="01:00:00"
